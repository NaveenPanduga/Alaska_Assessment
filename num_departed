from pyspark.sql.functions import col, lit, count
airlines_path = "/public/airlines_all/airlines-part/flightmonth=200801"
airport_codes_path = "/public/airlines_all/airport-codes"
airlines = spark.read.parquet(airlines_path)
airport_codes = spark.read.csv(airport_codes_path, sep="\t", header=True, inferSchema=True.filter("!(State = 'Hawaii' AND IATA = 'Big') AND Country='USA'")

join_flights = airlines.join(airport_codes, airport_codes.IATA == airlines.Origin)

flight_count_per_airport = join_flights.groupBy("Origin").agg(count(lit(1)).alias("FlightCount")).orderBy(col("FlightCount").desc())
flight_count_per_airport.show(10)
